log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = sigma)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the sample standard deviation (xsd)
geom_point(data = tibble::tibble(xbar = avg_hw06, xsd = sd_hw06),
mapping = aes(x = xbar, y = xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(sigma)) +
theme_bw()
my_cv_logpost <- function(unknowns, my_info)
{
# unpack the unknowns into separate variables
lik_mu <- unknowns[1]
lik_varphi <- unknowns[2]
# back transform to sigma
lik_sigma <- exp(lik_varphi)
# calculate the log-likelihood
log_lik <- sum(dnorm(my_info$xobs, mean = lik_mu, sd = lik_sigma, log = TRUE))
# calculate the log-prior on mu
log_prior_mu <- dnorm(lik_mu, mean = my_info$mu_0, sd = my_info$tau_0, log = TRUE)
# calculate the log-prior on sigma
log_prior_sigma <- dexp(lik_sigma, rate = my_info$sigma_rate, log = TRUE)
# calculate the log-derivative adjustment
log_deriv_adjust <- lik_varphi
# return the (un-normalized) log-posterior
return(log_lik + log_prior_mu + log_prior_sigma + log_deriv_adjust)
}
###
test_3d_01 <- c(13, 0)
my_cv_logpost(test_3d_01, hw06_info)
###
test_3d_02 <- c(7, -1)
my_cv_logpost(test_3d_02, hw06_info)
varphi_grid_lwr <- log(sigma_grid_lwr)
varphi_grid_upr <- log(sigma_grid_upr)
cv_param_grid <- expand.grid(mu = seq(from = mu_grid_lwr, to = mu_grid_upr, length.out = 251),
varphi = seq(from = varphi_grid_lwr, to = varphi_grid_upr, length.out = 251),
KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
as.data.frame() %>% tibble::as_tibble()
log_post_cv_result <- purrr::map2_dbl(cv_param_grid$mu, cv_param_grid$varphi,
eval_logpost,
logpost_func = my_cv_logpost,
logpost_info = hw06_info)
init_guess_01 <- c(10, 0.75)
init_guess_02 <- c(11.75, 1.85)
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the initial guess points
geom_point(data = tibble::tibble(attempt = as.character(1:2),
mu = c(10, 11.75),
varphi = c(0.75, 1.85)),
mapping = aes(color = attempt),
size = 4.5) +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
map_res_01 <- optim(init_guess_01,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
map_res_01
map_res_02 <- optim(init_guess_02,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
map_res_02
map_res_01$par
map_res_02$par
map_res_01$hessian
map_res_02$hessian
my_laplace <- function(start_guess, logpost_func, ...)
{
# code adapted from the `LearnBayes`` function `laplace()`
fit <- optim(start_guess,
logpost_func ,
gr = NULL,
...,
method = "BFGS",
hessian =  TRUE,
control = list(fnscale = -1, maxit = 5001))
mode <- fit$par
post_var_matrix <- -solve(fit$hessian)
p <- length(mode)
# we will discuss what int means in a few weeks...
int <- p/2 * log(2 * pi) + 0.5 * log(det(post_var_matrix)) + logpost_func(mode, ...)
# package all of the results into a list
list(mode = mode,
var_matrix = post_var_matrix,
log_evidence = int,
converge = ifelse(fit$convergence == 0,
"YES",
"NO"),
iter_counts = as.numeric(fit$counts[1]))
}
laplace_result <-  my_laplace(init_guess_01, my_cv_logpost, hw06_info)
laplace_result
laplace_result02 <-  my_laplace(init_guess_02, my_cv_logpost, hw06_info)
laplace_result02
p_s_d_mu <- sqrt(laplace_result$var_matrix[1])
p_s_d_mu
laplace_result_01 <- my_laplace(init_guess_01, my_cv_logpost, hw06_info)
laplace_result_02 <- my_laplace(init_guess_02, my_cv_logpost, hw06_info)
laplace_result_01$mode
laplace_result_02$mode
sqrt(laplace_result_01$var_matrix[1])
sqrt(laplace_result_01$var_matrix[1])
sqrt(laplace_result_01$var_matrix[4])
sqrt(laplace_result_01$var_matrix[1])
sqrt(laplace_result_01$var_matrix[1])
sqrt(laplace_result_01$var_matrix[1])
sqrt(laplace_result_02$var_matrix[1])
sqrt(laplace_result_01$var_matrix[4])
sqrt(laplace_result_02$var_matrix[4])
calcu_cor_coe = function(laplace_result){
return(laplace_result$var_matrix[2] / laplace_result$var_matrix[1]*laplace_result$var_matrix[4])
}
calcu_cor_coe(laplace_result_01)
calcu_cor_coe = function(laplace_result){
return(laplace_result$var_matrix[2] / laplace_result$var_matrix[1]*laplace_result$var_matrix[4])
}
calcu_cor_coe(laplace_result_01)
calcu_cor_coe(laplace_result_02)
s_xy <- laplace_result$var_matrix[2]
s_xy
r_xy <-  (s_xy / (p_s_d_mu * p_s_d_varphi))
p_s_d_varphi <- sqrt(laplace_result$var_matrix[4])
p_s_d_varphi
s_xy <- laplace_result$var_matrix[2]
s_xy
r_xy <-  (s_xy / (p_s_d_mu * p_s_d_varphi))
r_xy
calcu_cor_coe = function(laplace_result){
return(laplace_result$var_matrix[2] / (laplace_result$var_matrix[1]*laplace_result$var_matrix[4]))
}
calcu_cor_coe(laplace_result_01)
calcu_cor_coe(laplace_result_02)
calcu_cor_coe = function(laplace_result){
return(sqrt(laplace_result$var_matrix[2]) / (laplace_result$var_matrix[1]*laplace_result$var_matrix[4]))
}
calcu_cor_coe(laplace_result_01)
calcu_cor_coe(laplace_result_02)
calcu_cor_coe = function(laplace_result){
return(laplace_result$var_matrix[2] / (sqrt(laplace_result$var_matrix[1])*laplace_result$var_matrix[4]))
}
calcu_cor_coe(laplace_result_01)
calcu_cor_coe(laplace_result_02)
calcu_cor_coe = function(laplace_result){
return(laplace_result$var_matrix[2] / (sqrt(laplace_result$var_matrix[1])*sqrt(laplace_result$var_matrix[4])))
}
calcu_cor_coe(laplace_result_01)
calcu_cor_coe(laplace_result_02)
s_xy <- laplace_result$var_matrix[2]
r_xy <-  (s_xy / (p_s_d_mu * p_s_d_varphi))
s_xy <- laplace_result$var_matrix[2]
r_xy <-  (s_xy / (p_s_d_mu * p_s_d_varphi))
r_xy
sqrt(laplace_result_01$var_matrix[1][1])
sqrt(laplace_result_02$var_matrix[1])
sqrt(laplace_result_01$var_matrix[1])
sqrt(laplace_result_02$var_matrix[1])
pnorm(mean(hw06_info), mean = laplace_result$mode[1], sd = sqrt(laplace_result$var_matrix[1][1]))
pnorm(mean(hw06_df), mean = laplace_result$mode[1], sd = sqrt(laplace_result$var_matrix[1][1]))
pnorm(average_df, mean = laplace_result$mode[1], sd = sqrt(laplace_result$var_matrix[1][1]))
pnorm(average_df, mean = laplace_result$mode[1], sd = sqrt(laplace_result$var_matrix[1]))
generate_post_samples <- function(mvn_info, num_samples)
{
MASS::mvrnorm(n = num_samples,
mu = mvn_info$mode[1],
Sigma = mvn_info$mode[4]) %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(c("mu", "varphi")) %>%
mutate(sigma = exp(Sigma))
}
generate_post_samples <- function(mvn_info, num_samples)
{
MASS::mvrnorm(n = num_samples,
mu = mvn_info$mode[1],
Sigma = mvn_info$var_matrix) %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(c("mu", "varphi")) %>%
mutate(sigma = exp(varphi))
}
set.seed(202004)
post_samples <- generate_post_samples(laplace_result, 1e4)
?mvrnorm
generate_post_samples <- function(mvn_info, num_samples)
{
MASS::mvrnorm(n = num_samples,
mu = mvn_info$mode,
Sigma = mvn_info$var_matrix) %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(c("mu", "varphi")) %>%
mutate(sigma = exp(Sigma))
}
generate_post_samples <- function(mvn_info, num_samples)
{
MASS::mvrnorm(n = num_samples,
mu = mvn_info$mode,
Sigma = mvn_info$var_matrix) %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(c("mu", "varphi")) %>%
mutate(sigma = exp(varphi))
}
View(laplace_result)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
hw06_data_url <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/06/hw06_data.csv"
hw06_df <- readr::read_csv(hw06_data_url, col_names = TRUE)
hw06_df %>% glimpse()
average_df = mean(hw06_df$x)
sigma_df = sd(hw06_df$x)
max_df = max(hw06_df$x)
min_df = min(hw06_df$x)
print(average_df)
print(sigma_df)
print(max_df)
print(min_df)
hw06_info <- list(
xobs = hw06_df$x,### the meausrements
mu_0 = 11,### mu_0 value
tau_0 = 0.5,### tau_0 value
sigma_rate = 0.5### rate (lambda) on sigma
)
my_logpost <- function(unknowns, my_info)
{
# unpack the unknowns into separate variables
lik_mu <- unknowns[1]
lik_sigma <- unknowns[2]
# calculate the log-likelihood
log_lik <- sum(dnorm(x = my_info$xobs,
mean = lik_mu,
sd = lik_sigma,
log = TRUE))
# calculate the log-prior on mu
log_prior_mu <- dnorm(x = lik_mu,
mean = my_info$mu_0,
sd = my_info$tau_0,
log = TRUE)
# calculate the log-prior on sigma
log_prior_sigma <- dexp(x = lik_sigma, rate = my_info$sigma_rate, log = TRUE)
# return the (un-normalized) log-posterior
log_lik + log_prior_mu + log_prior_sigma
}
my_logpost(unknowns = c(13,5), my_info = hw06_info)
my_logpost(unknowns = c(7,1.5), my_info = hw06_info)
expand.grid(x1 = c(1, 2),
x2 = 1:3,
# extra arguments I like to set
KEEP.OUT.ATTRS = FALSE,
stringsAsFactors = FALSE) %>%
# convert to a tibble!
as.data.frame() %>% tibble::as_tibble()
mu_grid_lwr <- hw06_info$mu_0 - 3 * hw06_info$tau_0
mu_grid_upr <- hw06_info$mu_0 + 3 * hw06_info$tau_0
sigma_grid_lwr <- 1
sigma_grid_upr <- qexp(0.99, rate = 0.5)
param_grid <- expand.grid(mu = seq(from = mu_grid_lwr, to = mu_grid_upr, length.out = 251),
sigma = seq(from = sigma_grid_lwr, to = sigma_grid_upr, length.out = 251),
KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
as.data.frame() %>% tibble::as_tibble()
param_grid
eval_logpost <- function(unknown_1, unknown_2, logpost_func, logpost_info)
{
return(logpost_func(c(unknown_1, unknown_2), logpost_info))
}
eval_logpost(13, 5, my_logpost, hw06_info)
log_post_result <- purrr::map2_dbl(param_grid$mu, param_grid$sigma,
eval_logpost,
logpost_func = my_logpost,
logpost_info = hw06_info)
param_grid %>%
mutate(log_post = log_post_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = sigma)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the sample standard deviation (xsd)
geom_point(data = tibble::tibble(xbar = mean(hw06_info$xobs), xsd = sd(hw06_info$xobs) ),
mapping = aes(x = xbar, y = xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(sigma)) +
theme_bw()
my_cv_logpost <- function(unknowns, my_info)
{
# unpack the unknowns into separate variables
lik_mu <- unknowns[1]
lik_varphi <- unknowns[2]
# back transform to sigma
lik_sigma <- exp(lik_varphi)
# calculate the log-likelihood
log_lik <- sum(dnorm(my_info$xobs,
mean = lik_mu,
sd = lik_sigma,
log = TRUE))
# calculate the log-prior on mu
log_prior_mu <- dnorm(lik_mu,
mean = my_info$mu_0,
sd = my_info$tau_0,
log = TRUE)
# calculate the log-prior on sigma
log_prior_sigma <- dexp(lik_sigma,
rate = my_info$sigma_rate,
log = TRUE)
# calculate the log-derivative adjustment
log_deriv_adjust <-  lik_varphi
# return the (un-normalized) log-posterior
return(log_lik + log_prior_mu + log_prior_sigma + log_deriv_adjust)
}
my_cv_logpost(c(13, 0), hw06_info)
my_cv_logpost(c(7,-1), hw06_info)
varphi_grid_lwr <- log(sigma_grid_lwr)
varphi_grid_upr <- log(sigma_grid_upr)
cv_param_grid <- expand.grid(mu = seq(from = mu_grid_lwr, to = mu_grid_upr, length.out = 251),
varphi = seq(from = varphi_grid_lwr, to = varphi_grid_upr, length.out = 251),
KEEP.OUT.ATTRS = FALSE, stringsAsFactors = FALSE) %>%
as.data.frame() %>% tibble::as_tibble()
log_post_cv_result <- purrr::map2_dbl(
cv_param_grid$mu, cv_param_grid$varphi,
eval_logpost,
logpost_func = my_cv_logpost,
logpost_info = hw06_info
)
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the sample average (xbar) and the log-sample standard deviation (log_xsd)
geom_point(data = tibble::tibble(xbar = mean(hw06_info$xobs), log_xsd = log(sd(hw06_info$xobs)) ),
mapping = aes(x = xbar, y = log_xsd),
shape = 22,
size = 4.5, fill = "orange", color = "steelblue") +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
init_guess_01 <- c(10, 0.75)
init_guess_02 <- c(11.75, 1.85)
cv_param_grid %>%
mutate(log_post = log_post_cv_result,
log_post_2 = log_post - max(log_post)) %>%
ggplot(mapping = aes(x = mu, y = varphi)) +
geom_raster(mapping = aes(fill = log_post_2)) +
stat_contour(mapping = aes(z = log_post_2),
breaks = log(c(0.01/100, 0.01, 0.1, 0.5, 0.9)),
size = 2.2,
color = "black") +
# include the initial guess points
geom_point(data = tibble::tibble(attempt = as.character(1:2),
mu = c(10, 11.75),
varphi = c(0.75, 1.85)),
mapping = aes(color = attempt),
size = 4.5) +
scale_fill_viridis_c(guide = FALSE, option = "viridis",
limits = log(c(0.01/100, 1.0))) +
labs(x = expression(mu), y = expression(varphi)) +
theme_bw()
map_res_01 <- optim(
init_guess_01,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001)
)
map_res_02 <- optim(
init_guess_02,
my_cv_logpost,
gr = NULL,
hw06_info,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001)
)
map_res_02
map_res_01
my_laplace <- function(start_guess, logpost_func, ...)
{
# code adapted from the `LearnBayes`` function `laplace()`
fit <- optim(start_guess,
logpost_func,
gr = NULL,
...,
method = "BFGS",
hessian =  TRUE,
control = list(fnscale = -1, maxit = 5001))
mode <- fit$par
post_var_matrix <- -solve(fit$hessian)
p <- length(mode)
# we will discuss what int means in a few weeks...
int <- p/2 * log(2 * pi) + 0.5 * log(det(post_var_matrix)) + logpost_func(mode, ...)
# package all of the results into a list
list(mode = mode,
var_matrix = post_var_matrix,
log_evidence = int,
converge = ifelse(fit$convergence == 0,
"YES",
"NO"),
iter_counts = as.numeric(fit$counts[1]))
}
laplace_result_01 <- my_laplace(init_guess_01, my_cv_logpost, hw06_info)
laplace_result_02 <- my_laplace(init_guess_02, my_cv_logpost, hw06_info)
laplace_result_01$mode
laplace_result_02$mode
sqrt(laplace_result_01$var_matrix[1])
sqrt(laplace_result_02$var_matrix[1])
sqrt(laplace_result_01$var_matrix[4])
sqrt(laplace_result_02$var_matrix[4])
calcu_cor_coe = function(laplace_result){
return(laplace_result$var_matrix[2] / (sqrt(laplace_result$var_matrix[1])*sqrt(laplace_result$var_matrix[4])))
}
calcu_cor_coe(laplace_result_01)
calcu_cor_coe(laplace_result_02)
pnorm(average_df, mean = laplace_result$mode[1], sd = sqrt(laplace_result$var_matrix[1]))
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
generate_post_samples <- function(mvn_info, num_samples)
{
MASS::mvrnorm(n = num_samples,
mu = mvn_info$mode,
Sigma = mvn_info$var_matrix) %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(c("mu", "varphi")) %>%
mutate(sigma = exp(varphi))
}
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
summary(post_samples)
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
summary(post_samples)
exp(mean(psot_samples$varphi))
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
summary(post_samples)
exp(mean(post_samples$varphi))
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
summary(post_samples)
exp(mean(post_samples$varphi)) == mean(post_samples$sigma)
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
summary(post_samples)
exp(mean(post_samples$varphi))
mean(exp(post_samples$varphi))
set.seed(202004)
post_samples <- generate_post_samples(laplace_result_01, 1e4)
summary(post_samples)
#Inverse link function to posterior mean on varphi
exp(mean(post_samples$varphi))
#Posterior mean on sigma
mean(exp(post_samples$varphi))
post_samples %>%
ggplot(mapping = aes(x = mu)) +
geom_histogram(bins = 55)
post_samples %>%
ggplot(mapping = aes(x = sigma)) +
geom_histogram(bins = 55)
post_samples %>%
ggplot(mapping = aes(x = varphi)) +
geom_histogram(bins = 55)
post_samples %>%
ggplot(mapping = aes(x = sigma)) +
geom_histogram(bins = 55)
post_samples %>%
ggplot(mapping = aes(x = sigma), bins = 55) +
geom_histogram()
post_samples %>%
ggplot(mapping = aes(x = sigma)) +
geom_histogram(bins = 55)
pnorm(average_df, mean = laplace_result_01$mode[1], sd = sqrt(laplace_result_01$var_matrix[1]))
post_samples
?filter
filter(post_samples, sigma > 4)
count(filter(post_samples, sigma > 4))
count(filter(post_samples, sigma > 4)) / count(post_samples)
prob = count(filter(post_samples, sigma > 4)) / count(post_samples)
prob
