data = prob_high_noise
)
mod_high_9
high_noise_results = resamples(list(fit_01 = mod_high_1,
fit_02 = mod_high_2,
fit_03 = mod_high_3,
fit_04 = mod_high_4,
fit_05 = mod_high_5,
fit_06 = mod_high_6,
fit_07 = mod_high_7,
fit_08 = mod_high_8,
fit_09 = mod_high_9))
### dotplot for your specified primary performance metric
dotplot(high_noise_results, metric = my_metric)
### dotplot for another performance metric
dotplot(high_noise_results, metric = "MAE")
### your code here
library(coefplot)
multiplot(mod_high_4$finalModel, mod_high_5$finalModel, mod_high_6$finalModel)
low_noise_github_file <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/02/prob_low_noise_dataset.csv"
prob_low_noise <- readr::read_csv(low_noise_github_file, col_names = TRUE)
prob_low_noise %>% glimpse()
### your code here
prob_low_noise %>%
ggplot(mapping = aes(x = x, y= y))+
geom_point()
### linear relationship
set.seed(2001)
mod_low_1 <- train(
y ~ x,
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### quadratic relationship
set.seed(2001)
mod_low_2 <- train(
y ~ x+I(x^2),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### cubic relationship
set.seed(2001)
mod_low_3 <- train(
y ~ x+I(x^2)+I(x^3),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 4th order
set.seed(2001)
mod_low_4 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 5th order
set.seed(2001)
mod_low_5 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 6th order
set.seed(2001)
mod_low_6 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 7th order
set.seed(2001)
mod_low_7 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 8th order
set.seed(2001)
mod_low_8 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7)+I(x^8),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 9th order
set.seed(2001)
mod_low_9 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7)+I(x^8)+I(x^9),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
low_noise_results = resamples(list(fit_01 = mod_low_1,
fit_02 = mod_low_2,
fit_03 = mod_low_3,
fit_04 = mod_low_4,
fit_05 = mod_low_5,
fit_06 = mod_low_6,
fit_07 = mod_low_7,
fit_08 = mod_low_8,
fit_09 = mod_low_9))
binary_class_data_url <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/02/hw02_binary_class.csv"
model_pred_df <- readr::read_csv(binary_class_data_url, col_names = TRUE)
model_pred_df %>% glimpse()
model_pred_df
### your code here
model_pred_df %>% count()
### your code here
mean(model_pred_df$obs_class == "event" )
iris %>%
slice(1:10) %>%
select(starts_with("Sepal"), Species) %>%
mutate(width_factor = ifelse(Sepal.Width > 3.5,
"greater than",
"less than"))
model_pred_df <- mutate(model_pred_df, y=ifelse(obs_class == "event", 1, 0))
model_pred_df
### your code here
model_pred_df %>%
ggplot()+
geom_point(mapping = aes(x=x, y=y, size=3.5, alpha = 0.5))
### your code here
summary(model_pred_df)
### your code here
model_pred_df %>%
ggplot()+
geom_point(mapping = aes(x=x, y=y, size=3.5, alpha = 0.5))+
geom_line(mapping = aes(x=x, y=pred_prob, color="red"))
model_class_0.5 <-
mutate(
model_pred_df,
pred_class = ifelse(pred_prob>0.5, "event", "non_event")
)
model_class_0.5
### your code here
model_class_0.5 %>%
summarise(accuracy = sum(obs_class == pred_class) / n())
### your code here
model_class_0.5 %>%
count(pred_class, obs_class)
### add more code chunks if you need to
TP = sum(model_class_0.5$obs_class == "event" & model_class_0.5$pred_class == "event")
TPFN = sum(model_class_0.5$obs_class == "event")
TN = sum(model_class_0.5$obs_class == "non_event" & model_class_0.5$pred_class == "non_event")
TNFP = sum(model_class_0.5$obs_class == "non_event")
SENSIT_0.5 = (TP / TPFN)
FPR_0.5 = 1 - (TN / TNFP)
#Sensitivity
SENSIT_0.5
#FPR
FPR_0.5
model_class_0.7 <- model_pred_df %>% mutate(pred_class = ifelse(pred_prob>0.7, "event", "non_event"))
model_class_0.7
model_class_0.3 <- model_pred_df %>% mutate(pred_class = ifelse(pred_prob>0.3, "event", "non_event"))
model_class_0.3
### your code here
model_class_0.7 %>%
summarise(accuracy = sum(obs_class == pred_class) / n())
### add more code chunks if you need to
TP = sum(model_class_0.7$obs_class == "event" & model_class_0.7$pred_class == "event")
TPFN = sum(model_class_0.7$obs_class == "event")
TN = sum(model_class_0.7$obs_class == "non_event" & model_class_0.7$pred_class == "non_event")
TNFP = sum(model_class_0.7$obs_class == "non_event")
SENSIT_0.7 = (TP / TPFN)
SPECIF_0.7 = (TN / TNFP)
#Sensitivity
SENSIT_0.7
#Specificity
SPECIF_0.7
### your code here
model_class_0.3 %>%
summarise(accuracy = sum(obs_class == pred_class) / n())
### add more code chunks if you need to
TP = sum(model_class_0.3$obs_class == "event" & model_class_0.3$pred_class == "event")
TPFN = sum(model_class_0.3$obs_class == "event")
TN = sum(model_class_0.3$obs_class == "non_event" & model_class_0.3$pred_class == "non_event")
TNFP = sum(model_class_0.3$obs_class == "non_event")
SENSIT_0.3 = (TP / TPFN)
SPECIF_0.3 = (TN / TNFP)
#Sensitivity
SENSIT_0.3
#Specificity
SPECIF_0.3
low_noise_results = resamples(list(fit_01 = mod_low_1,
fit_02 = mod_low_2,
fit_03 = mod_low_3,
fit_04 = mod_low_4,
fit_05 = mod_low_5,
fit_06 = mod_low_6,
fit_07 = mod_low_7,
fit_08 = mod_low_8,
fit_09 = mod_low_9))
dotplot(low_noise_results, metric = "RMSE")
dotplot(low_noise_results, metric = "MAE")
model_pred_df %>% glimpse()
model_pred_df
model_pred_df %>% glimpse()
### you may add more code chunks if you need to
my_data = data.frame(sensitivity = c(SENSIT_0.3,SENSIT_0.5,SENSIT_0.7), FPR = c(1-SPECIF_0.3, FPR_0.5, 1-SPECIF_0.7))
my_data %>%
ggplot(mapping = aes(x = FPR, y = sensitivity)) +
geom_point() +
geom_abline(slope = 1, intercept = 0) +
coord_equal(xlim=c(0,1), ylim=c(0,1))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(caret)
high_noise_github_file <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/02/prob_high_noise_dataset.csv"
prob_high_noise <- readr::read_csv(high_noise_github_file,
col_names = TRUE)
prob_high_noise %>% glimpse()
### your code here
prob_high_noise %>%
ggplot() +
geom_point(mapping = aes(x = x, y = y))
### load in the caret library
library(caret)
my_ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
my_metric <- "RMSE"
### linear relationship
set.seed(2001)
mod_high_1 <- train(y ~ x, method = "lm", metric = my_metric, trControl = my_ctrl, data = prob_high_noise)
mod_high_1
### quadratic relationship
set.seed(2001)
mod_high_2 <- train(
y ~ x+I(x^2),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_2
### cubic relationship
set.seed(2001)
mod_high_3 <- train(
y ~ x+I(x^2)+I(x^3),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_3
### 4th order
set.seed(2001)
mod_high_4 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_4
### 5th order
set.seed(2001)
mod_high_5 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_5
### 6th order
set.seed(2001)
mod_high_6 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_6
### 7th order
set.seed(2001)
mod_high_7 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_7
### 8th order
set.seed(2001)
mod_high_8 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7)+I(x^8),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_8
### 9th order
set.seed(2001)
mod_high_9 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7)+I(x^8)+I(x^9),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_high_noise
)
mod_high_9
high_noise_results = resamples(list(fit_01 = mod_high_1,
fit_02 = mod_high_2,
fit_03 = mod_high_3,
fit_04 = mod_high_4,
fit_05 = mod_high_5,
fit_06 = mod_high_6,
fit_07 = mod_high_7,
fit_08 = mod_high_8,
fit_09 = mod_high_9))
### dotplot for your specified primary performance metric
dotplot(high_noise_results, metric = my_metric)
### dotplot for another performance metric
dotplot(high_noise_results, metric = "MAE")
### your code here
library(coefplot)
multiplot(mod_high_4$finalModel, mod_high_5$finalModel, mod_high_6$finalModel)
low_noise_github_file <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/02/prob_low_noise_dataset.csv"
prob_low_noise <- readr::read_csv(low_noise_github_file, col_names = TRUE)
prob_low_noise %>% glimpse()
### your code here
prob_low_noise %>%
ggplot(mapping = aes(x = x, y= y))+
geom_point()
### linear relationship
set.seed(2001)
mod_low_1 <- train(
y ~ x,
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### quadratic relationship
set.seed(2001)
mod_low_2 <- train(
y ~ x+I(x^2),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### cubic relationship
set.seed(2001)
mod_low_3 <- train(
y ~ x+I(x^2)+I(x^3),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 4th order
set.seed(2001)
mod_low_4 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 5th order
set.seed(2001)
mod_low_5 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 6th order
set.seed(2001)
mod_low_6 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 7th order
set.seed(2001)
mod_low_7 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 8th order
set.seed(2001)
mod_low_8 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7)+I(x^8),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
### 9th order
set.seed(2001)
mod_low_9 <- train(
y ~ x+I(x^2)+I(x^3)+I(x^4)+I(x^5)+I(x^6)+I(x^7)+I(x^8)+I(x^9),
method = "lm",
metric = my_metric,
trControl = my_ctrl,
data = prob_low_noise
)
low_noise_results = resamples(list(fit_01 = mod_low_1,
fit_02 = mod_low_2,
fit_03 = mod_low_3,
fit_04 = mod_low_4,
fit_05 = mod_low_5,
fit_06 = mod_low_6,
fit_07 = mod_low_7,
fit_08 = mod_low_8,
fit_09 = mod_low_9))
binary_class_data_url <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/02/hw02_binary_class.csv"
model_pred_df <- readr::read_csv(binary_class_data_url, col_names = TRUE)
model_pred_df %>% glimpse()
### your code here
model_pred_df %>% count()
### your code here
mean(model_pred_df$obs_class == "event" )
iris %>%
slice(1:10) %>%
select(starts_with("Sepal"), Species) %>%
mutate(width_factor = ifelse(Sepal.Width > 3.5,
"greater than",
"less than"))
model_pred_df <- mutate(model_pred_df, y=ifelse(obs_class == "event", 1, 0))
model_pred_df
### your code here
model_pred_df %>%
ggplot()+
geom_point(mapping = aes(x=x, y=y, size=3.5, alpha = 0.5))
### your code here
summary(model_pred_df)
### your code here
model_pred_df %>%
ggplot()+
geom_point(mapping = aes(x=x, y=y, size=3.5, alpha = 0.5))+
geom_line(mapping = aes(x=x, y=pred_prob, color="red"))
model_class_0.5 <-
mutate(
model_pred_df,
pred_class = ifelse(pred_prob>0.5, "event", "non_event")
)
model_class_0.5
### your code here
model_class_0.5 %>%
summarise(accuracy = sum(obs_class == pred_class) / n())
### your code here
model_class_0.5 %>%
count(pred_class, obs_class)
### add more code chunks if you need to
TP = sum(model_class_0.5$obs_class == "event" & model_class_0.5$pred_class == "event")
TPFN = sum(model_class_0.5$obs_class == "event")
TN = sum(model_class_0.5$obs_class == "non_event" & model_class_0.5$pred_class == "non_event")
TNFP = sum(model_class_0.5$obs_class == "non_event")
SENSIT_0.5 = (TP / TPFN)
FPR_0.5 = 1 - (TN / TNFP)
#Sensitivity
SENSIT_0.5
#FPR
FPR_0.5
model_class_0.7 <- model_pred_df %>% mutate(pred_class = ifelse(pred_prob>0.7, "event", "non_event"))
model_class_0.7
model_class_0.3 <- model_pred_df %>% mutate(pred_class = ifelse(pred_prob>0.3, "event", "non_event"))
model_class_0.3
### your code here
model_class_0.7 %>%
summarise(accuracy = sum(obs_class == pred_class) / n())
### add more code chunks if you need to
TP = sum(model_class_0.7$obs_class == "event" & model_class_0.7$pred_class == "event")
TPFN = sum(model_class_0.7$obs_class == "event")
TN = sum(model_class_0.7$obs_class == "non_event" & model_class_0.7$pred_class == "non_event")
TNFP = sum(model_class_0.7$obs_class == "non_event")
SENSIT_0.7 = (TP / TPFN)
SPECIF_0.7 = (TN / TNFP)
#Sensitivity
SENSIT_0.7
#Specificity
SPECIF_0.7
### your code here
model_class_0.3 %>%
summarise(accuracy = sum(obs_class == pred_class) / n())
### add more code chunks if you need to
TP = sum(model_class_0.3$obs_class == "event" & model_class_0.3$pred_class == "event")
TPFN = sum(model_class_0.3$obs_class == "event")
TN = sum(model_class_0.3$obs_class == "non_event" & model_class_0.3$pred_class == "non_event")
TNFP = sum(model_class_0.3$obs_class == "non_event")
SENSIT_0.3 = (TP / TPFN)
SPECIF_0.3 = (TN / TNFP)
#Sensitivity
SENSIT_0.3
#Specificity
SPECIF_0.3
