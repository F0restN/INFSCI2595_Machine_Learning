geom_point(mapping = aes(x=x, y=y, size=4, alpha=0.33))
train_df %>%
ggplot()+
geom_point(mapping = aes(x=x, y=y, size=4, alpha=0.33))
train_df %>%
ggplot()+
geom_jitter(mapping = aes(x=x, y=y), height = 0.02, width = 0)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
train_data_url <- 'https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/09/hw09_binary_01.csv'
train_df <- readr::read_csv(train_data_url, col_names = TRUE)
train_df %>% glimpse()
train_df %>% count(y)
train_df %>%
ggplot()+
geom_point(mapping = aes(x=x, y=y, size=4, alpha=0.33))
train_df %>%
ggplot()+
geom_jitter(mapping = aes(x=x, y=y), height = 0.02, width = 0)
Xmat_linear <- model.matrix(y ~ x, train_df)
Xmat_cubic <- model.matrix(y ~ x + I(x^2) + I(x^3), train_df)
Xmat_spline7 <- model.matrix(y ~ spline::ns(x, 7), train_df)
Xmat_linear <- model.matrix(y ~ x, train_df)
Xmat_cubic <- model.matrix(y ~ x + I(x^2) + I(x^3), train_df)
Xmat_spline7 <- model.matrix(y ~ splines::ns(x, 7), train_df)
info_linear <- list(
yobs = train_df$y,
design_matrix = Xmat_linear,
mu_beta = 0,
tau_beta = 5
)
info_cubic <- list(
yobs = train_df$y,
design_matrix = Xmat_cubic,
mu_beta = 0,
tau_beta = 5
)
info_spline7 <- list(
yobs = train_df$y,
design_matrix = Xmat_spline7,
mu_beta = 0,
tau_beta = 5
)
logistic_logpost <- function(unknowns, my_info)
{
# extract the design matrix and assign to X
X <- my_info$design_matrix
# calculate the linear predictor
eta <- as.vector(X %*% matrix(unknowns))
# calculate the event probability
mu <- boot::inv.logit(eta)
# evaluate the log-likelihood
log_lik <- sum(dbinom(x = my_info$yobs,
size = 1,
prob = mu,
log = TRUE))
# evaluate the log-prior
log_prior <- sum(dnorm(x = unknowns,
mean = my_info$mu_beta,
sd = my_info$tau_beta,
log = TRUE))
# sum together
log_lik + log_prior
}
###
logistic_logpost(rep(-1, ncol(Xmat_linear)), info_linear)
###
logistic_logpost(rep(2, ncol(Xmat_linear)), info_linear)
my_laplace <- function(start_guess, logpost_func, ...)
{
# code adapted from the `LearnBayes`` function `laplace()`
fit <- optim(start_guess,
logpost_func,
gr = NULL,
...,
method = "BFGS",
hessian = TRUE,
control = list(fnscale = -1, maxit = 1001))
mode <- fit$par
post_var_matrix <- -solve(fit$hessian)
p <- length(mode)
int <- p/2 * log(2 * pi) + 0.5 * log(det(post_var_matrix)) + logpost_func(mode, ...)
# package all of the results into a list
list(mode = mode,
var_matrix = post_var_matrix,
log_evidence = int,
converge = ifelse(fit$convergence == 0,
"YES",
"NO"),
iter_counts = as.numeric(fit$counts[1]))
}
laplace_linear <- my_laplace(rep(0, ncol(Xmat_linear)), logistic_logpost, info_linear)
laplace_cubic <- my_laplace(rep(0, nocl(Xmat_cubic)), logistic_logpost, info_cubic)
laplace_linear <- my_laplace(rep(0, ncol(Xmat_linear)), logistic_logpost, info_linear)
laplace_cubic <- my_laplace(rep(0, ncol(Xmat_cubic)), logistic_logpost, info_cubic)
laplace_spline7 <- my_laplace(rep(0, ncol(Xmat_spline7)), logistic_logpost, info_spline7)
###
upper_line <- laplace_linear$mode + 2 * sqrt(diag(laplace_linear$var_matrix))
lower_line <- laplace_linear$mode- 2 * sqrt(diag(laplace_linear$var_matrix))
upper_line
lower_line
###
upper_cubic <- laplace_cubic$mode+2*sqrt(diag(laplace_cubic$var_matrix))
lower_cubic <- laplace_cubic$mode-2*sqrt(diag(laplace_cubic$var_matrix))
upper_cubic
lower_cubic
###
upper_cubic <- laplace_cubic$mode+2*sqrt(diag(laplace_cubic$var_matrix))
lower_cubic <- laplace_cubic$mode-2*sqrt(diag(laplace_cubic$var_matrix))
upper_cubic
lower_cubic
###
upper_line <- laplace_linear$mode + 2 * sqrt(diag(laplace_linear$var_matrix))
lower_line <- laplace_linear$mode- 2 * sqrt(diag(laplace_linear$var_matrix))
upper_line
lower_line
###
weight_linear <- exp(laplace_linear$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_linear
weight_cubic <- exp(laplace_cubic$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_cubic
weight_splines <- exp(laplace_spline7$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_splines
###
log_evidence_linear <- exp(laplace_linear$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_linear
log_evidence_cubic <- exp(laplace_cubic$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_cubic
log_evidence_splines <- exp(laplace_spline7$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_splines
###
weight_linear <- exp(laplace_linear$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_linear
weight_cubic <- exp(laplace_cubic$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_cubic
weight_splines <- exp(laplace_spline7$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_splines
###
weight_linear <- exp(laplace_linear$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_linear
weight_cubic <- exp(laplace_cubic$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_cubic
weight_splines <- exp(laplace_spline7$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_splines
###
weight_linear <- exp(laplace_linear$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_linear
weight_cubic <- exp(laplace_cubic$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_cubic
weight_splines <- exp(laplace_spline7$log_evidence) / (exp(laplace_linear$log_evidence) + exp(laplace_cubic$log_evidence) + exp(laplace_spline7$log_evidence))
weight_splines
generate_glm_post_samples <- function(mvn_result, num_samples)
{
# specify the number of unknown beta parameters
length_beta <- length(mvn_result$mode)
# generate the random samples
beta_samples <- MASS::mvrnorm(n = num_samples,
mu = mvn_result$mode,
Sigma = mvn_result$var_matrix)
# change the data type and name
beta_samples %>%
as.data.frame() %>% tibble::as_tibble() %>%
purrr::set_names(sprintf("beta_%02d", (1:length_beta) - 1))
}
post_logistic_pred_samples <- function(Xnew, Bmat)
{
# calculate the linear predictor at all prediction points and posterior samples
eta_mat <- Xnew %*% t(Bmat)
# calculate the event probability
mu_mat <- boot::inv.logit(eta_mat)
# book keeping
list(eta_mat = eta_mat, mu_mat = mu_mat)
}
summarize_logistic_pred_from_laplace <- function(mvn_result, Xtest, num_samples)
{
# generate posterior samples of the beta parameters
betas <- generate_glm_post_samples(mvn_result, num_samples)
# data type conversion
betas <- as.matrix(betas)
# make posterior predictions on the test set
pred_test <- post_logistic_pred_samples(Xtest, betas)
# calculate summary statistics on the posterior predicted probability
# summarize over the posterior samples
# posterior mean, should you summarize along rows (rowMeans) or
# summarize down columns (colMeans) ???
mu_avg <- rowMeans(pred_test$mu_mat)
# posterior quantiles
mu_q05 <- apply(pred_test$mu_mat, 1, stats::quantile, probs = 0.05)
mu_q95 <- apply(pred_test$mu_mat, 1, stats::quantile, probs = 0.95)
# book keeping
tibble::tibble(
mu_avg = mu_avg,
mu_q05 = mu_q05,
mu_q95 = mu_q95
) %>%
tibble::rowid_to_column("pred_id")
}
set.seed(8123)
post_pred_summary_linear <- summarize_logistic_pred_from_laplace(laplace_linear, Xmat_linear, 2500)
post_pred_summary_cubic <- summarize_logistic_pred_from_laplace(laplace_cubic, Xmat_cubic, 2500)
post_pred_summary_spline7 <- summarize_logistic_pred_from_laplace(laplace_spline7, Xmat_spline7, 2500)
post_pred_summary_linear
###
dim(post_pred_summary_linear)
dim(post_pred_summary_cubic)
dim(post_pred_summary_spline7)
post_pred_summary_linear %>%
mutate(type = "linear relationship") %>%
bind_rows(post_pred_summary_cubic %>%
mutate(type = "cubic relationship")) %>%
bind_rows(post_pred_summary_spline7 %>%
mutate(type = "7 dof spline")) %>%
left_join(train_df %>% tibble::rowid_to_column("pred_id"),
by = "pred_id") %>%
ggplot(mapping = aes(x = x)) +
geom_ribbon(mapping = aes(ymin = mu_q05,
ymax = mu_q95,
group = type),
fill = "steelblue", alpha = 0.5) +
geom_line(mapping = aes(y = mu_avg,
group = type),
color = "navyblue", size = 1.15) +
geom_point(mapping = aes(y = y),
size = 2.5, alpha = 0.2) +
facet_grid( . ~ type) +
labs(y = "y or event probability") +
theme_bw()
post_pred_summary_linear_class <- post_pred_summary_linear %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_cubic_class <- post_pred_summary_cubic %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_spline7_class <- post_pred_summary_spline7 %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_linear_class
post_pred_summary_linear_class_b <- post_pred_summary_linear_class %>%
left_join(train_df %>% tibble::rowid_to_column("pred_id"),
by = "pred_id")
post_pred_summary_cubic_class_b <- post_pred_summary_cubic_class %>%
left_join(train_df %>% tibble::rowid_to_column("pred_id"),
by = "pred_id")
post_pred_summary_spline7_class_b <- post_pred_summary_spline7_class %>%
left_join(train_df %>% tibble::rowid_to_column("pred_id"),
by = "pred_id")
post_pred_summary_linear_class <- post_pred_summary_linear %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_cubic_class <- post_pred_summary_cubic %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_spline7_class <- post_pred_summary_spline7 %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_linear_class
post_pred_summary_linear_class <- post_pred_summary_linear %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_cubic_class <- post_pred_summary_cubic %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_spline7_class <- post_pred_summary_spline7 %>% mutate(pred_class = ifelse(mu_avg > 0.5, 1, 0))
post_pred_summary_linear_class
post_pred_summary_linear_class_b <- post_pred_summary_linear_class %>%
left_join(train_df %>% tibble::rowid_to_column("pred_id"),
by = "pred_id")
post_pred_summary_cubic_class_b <- post_pred_summary_cubic_class %>%
left_join(train_df %>% tibble::rowid_to_column("pred_id"),
by = "pred_id")
post_pred_summary_spline7_class_b <- post_pred_summary_spline7_class %>%
left_join(train_df %>% tibble::rowid_to_column("pred_id"),
by = "pred_id")
###
post_pred_summary_linear_class_b %>% count((pred_class == 1) & (y == 1), ((pred_class == 0) & (y == 0)), (pred_class == 1) & (y == 0), (pred_class == 0) & (y == 1))
###
post_pred_summary_cubic_class_b %>% count((pred_class == 1) & (y == 1), ((pred_class == 0) & (y == 0)), (pred_class == 1) & (y == 0), (pred_class == 0) & (y == 1))
###
post_pred_summary_linear_class_b %>% count((pred_class == 1) & (y == 1), ((pred_class == 0) & (y == 0)), (pred_class == 1) & (y == 0), (pred_class == 0) & (y == 1))
###
post_pred_summary_spline7_class_b %>% count((pred_class == 1) & (y == 1), ((pred_class == 0) & (y == 0)), (pred_class == 1) & (y == 0), (pred_class == 0) & (y == 1))
ac_linear <- (63+16) / (63+16+34+12)
ac_cubic <- (57+31) / (63+16+34+12)
ac_splines <- (62+29) / (63+16+34+12)
ac_linear <- (63+16) / 125
ac_cubic <- (57+31) / 125
ac_splines <- (62+29) / 125
ac_linear <- (63+16) / 125
ac_cubic <- (57+31) / 125
ac_splines <- (62+29) / 125
ac_linear
ac_cubic
ac_splines
small_data_url <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/09/hw09_binary_02.csv"
train_small <- readr::read_csv( small_data_url )
train_small %>% glimpse()
small_data_url <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/09/hw09_binary_02.csv"
train_small <- readr::read_csv( small_data_url )
train_small %>% glimpse()
###
train_small %>%
ggplot(mapping = aes(x = x, y = y)) +
geom_point(color = "blue") +
geom_vline(xintercept = -0.6, color = "orange")
###
train_small %>%
ggplot(mapping = aes(x = x, y = y)) +
geom_point(color = "blue") +
geom_vline(xintercept = -0.6, color = "yellow")
small_laplace_from_inform <- my_laplace(rep(0, ncol(Xmat)), logistic_logpost, info_small_inform)
Xmat <- model.matrix(y ~ x, data = train_small)
info_small_inform <- list(
yobs = train_small$y,
design_matrix = Xmat,
mu_beta = 0,
tau_beta = 2.5
)
info_small_weak <- list(
yobs = train_small$y,
design_matrix = Xmat,
mu_beta = 0,
tau_beta = 50
)
small_laplace_from_inform <- my_laplace(rep(0, ncol(Xmat)), logistic_logpost, info_small_inform)
small_laplace_from_inform$mode
small_laplace_from_weak <- my_laplace(rep(0, ncol(Xmat)), logistic_logpost, info_small_weak)
small_laplace_from_weak$mode
cor_info <- small_laplace_from_inform$var_matrix %>% cov2cor()
corrplot::corrplot(cor_info)
###
mod_small_mle <- glm(y ~ x, family = "binomial", data = train_small)
coefplot(mod_small_mle)
###
mod_small_mle <- glm(y ~ x, family = "binomial", data = train_small)
mod_small_mle %>% coef()
summary(mod_small_mle)
data_url <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Spring_2022/main/HW/09/hw09_regression.csv"
df <- readr::read_csv(data_url, col_names = TRUE)
df %>% glimpse()
### add more code chunks if you like
df %>%
pivot_longer(!y, names_to="x", values_to="value") %>%
ggplot() +
geom_point(mapping = aes(x = value, y = y), color = 'blue') +
geom_smooth(mapping = aes(x = value, y = y), color = "red") +
facet_wrap(~x)
### add more code chunks if you like
df %>%
ggplot() +
geom_point(mapping = aes(x = value, y = y), color = 'blue') +
geom_smooth(mapping = aes(x = value, y = y), color = "red") +
facet_wrap(~x)
### add more code chunks if you like
df %>%
pivot_longer(!y, names_to="x", values_to="value") %>%
ggplot() +
geom_point(mapping = aes(x = value, y = y), color = 'blue') +
geom_smooth(mapping = aes(x = value, y = y), color = "red") +
facet_wrap(~x)
### add more code chunks if you like
df %>%
pivot_longer(!y, names_to="x", values_to="value") %>%
ggplot() +
geom_point(mapping = aes(x = value, y = y), color = 'blue') +
geom_smooth(mapping = aes(x = value, y = y), color = "red") +
facet_wrap(~x)
### add more code chunks if you like
df %>%
pivot_longer(!y, names_to="x", values_to="value") %>%
ggplot() +
geom_point(mapping = aes(x = value, y = y), color = 'blue') +
geom_smooth(mapping = aes(x = value, y = y), color = "red") +
### add more code chunks if you like
df %>%
pivot_longer(!y, names_to="x", values_to="value") %>%
ggplot() +
geom_point(mapping = aes(x = value, y = y), color = 'blue') +
geom_smooth(mapping = aes(x = value, y = y), color = "red")
### add more code chunks if you like
df %>%
pivot_longer(!y, names_to="x", values_to="value") %>%
ggplot() +
geom_point(mapping = aes(x = value, y = y), color = 'blue') +
geom_smooth(mapping = aes(x = value, y = y), color = "red") +
facet_wrap(~x)
### add more code chunks if you like
df %>%
select(-y) %>%
cor()
### first corrplot
df %>%
select(-y) %>%
cor() %>%
corrplot()
install(corrplot)
### first corrplot
df %>%
select(-y) %>%
cor() %>%
corrplot::corrplot()
### first corrplot
df %>%
select(-y) %>%
cor() %>%
corrplot()
library(caret)
library(corrplot)
### first corrplot
df %>%
select(-y) %>%
cor() %>%
corrplot()
### second corrplot
df %>%
select(-y) %>%
cor() %>%
corrplot(type = 'upper')
### add as many code chunks as you feel are necessary
mod01 <- (model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = df))
SSmat <- t(mod01) %*% mod01
SSmat %>%
solve() %>%
cov2cor() %>%
corrplot(type = 'upper')
### add as many code chunks as you feel are necessary
mod01 <- (model.matrix(y ~ x1 + x2 + x3 + x4 + x5 + x6, data = df))
SSmat <- t(mod01) %*% mod01
SSmat %>%
solve() %>%
cov2cor() %>%
corrplot(type = 'upper')
### add your code here
Xtrips <- model.matrix(y ~ (.)^3, df)
### add as many code chunks as you'd like
SSmat <- t(Xtrips) %*% Xtrips;
matrix01f <- SSmat %>%
solve() %>%
cov2cor() %>%
corrplot(type = 'upper', method = 'square')
library(caret)
library(corrplot)
library(caret)
library(corrplot)
### your code here
my_ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
my_metric <- "RMSE"
### your code here
enet_default <- train(y ~ (.)^3,
data = df,
method = "glmnet",
metric = my_metric,
preProcess = c("center", "scale"),
trControl = my_ctrl)
enet_default
### your code here
enet_grid <- expand.grid(alpha = seq(0.1, 0.9, length.out = 9),
lambda = exp(seq(log(min(enet_default$results$lambda)),
log(max(enet_default$results$lambda)),
length.out = 25)))
enet_grid %>% nrow()
### add more code chunks if you'd like
enet_tune <- train(y ~ (.)^3,
data = df,
method = "glmnet",
metric = my_metric,
preProcess = c("center", "scale"),
trControl = my_ctrl,
tuneGrid = enet_grid)
### add more code chunks if you'd like
enet_tune <- train(y ~ (.)^3,
data = df,
method = "glmnet",
metric = my_metric,
preProcess = c("center", "scale"),
trControl = my_ctrl,
tuneGrid = enet_grid)
enet_tune %>% plot(xTrans = log)
enet_tune$bestTune
### add more code chunks if you'd like
coef(enet_tune$finalModel, s = enet_tune$bestTune$lambda)
plot(varImp(enet_tune))
### add your code here
Xtrips <- model.matrix(y ~ (.)^3, df)
### add as many code chunks as you'd like
SSmat <- t(Xtrips) %*% Xtrips;
matrix01f <- SSmat %>%
solve() %>%
cov2cor() %>%
corrplot(type = 'upper', method = 'square')
### add as many code chunks as you'd like
SSmat <- t(Xtrips) %*% Xtrips;
matrix01f <- SSmat %>%
solve() %>%
cov2cor() %>%
corrplot(type = 'upper', method = 'square')
library(caret)
library(corrplot)
### your code here
my_ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 5)
my_metric <- "RMSE"
### your code here
enet_default <- train(y ~ (.)^3,
data = df,
method = "glmnet",
metric = my_metric,
preProcess = c("center", "scale"),
trControl = my_ctrl)
enet_default
### your code here
enet_grid <- expand.grid(alpha = seq(0.1, 0.9, length.out = 9),
lambda = exp(seq(log(min(enet_default$results$lambda)),
log(max(enet_default$results$lambda)),
length.out = 25)))
enet_grid %>% nrow()
###
mod_small_mle <- glm(y ~ x, family = "binomial", data = train_small)
mod_small_mle %>% coef()
summary(mod_small_mle)
cor_info <- small_laplace_from_inform$var_matrix %>% cov2cor()
corrplot(cor_info)
cor_weak <- small_laplace_from_weak$var_matrix %>% cov2cor()
corrplot(cor_weak)
df <- readr::read_csv(data_url, col_names = TRUE)
data_url <- "https://raw.githubusercontent.com/jyurko/INFSCI_2595_Fall_2021/main/HW/09/hw09.csv"
df <- readr::read_csv(data_url, col_names = TRUE)
head(df)
matrix <- lm(y ~ x1 + x2, data = df)
head(matrix)
